{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test precedure for 4 european countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### don t forget: UK and US might have several names in different languages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sqlalchemy import create_engine\n",
    "import zipfile\n",
    "import tarfile\n",
    "import bz2\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File ./data/country_names_multilingual/IP2LOCATION-COUNTRY-MULTILINGUAL.CSV does not exist: './data/country_names_multilingual/IP2LOCATION-COUNTRY-MULTILINGUAL.CSV'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b7462b45450c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mc_multilingu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/country_names_multilingual/IP2LOCATION-COUNTRY-MULTILINGUAL.CSV'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File ./data/country_names_multilingual/IP2LOCATION-COUNTRY-MULTILINGUAL.CSV does not exist: './data/country_names_multilingual/IP2LOCATION-COUNTRY-MULTILINGUAL.CSV'"
     ]
    }
   ],
   "source": [
    "c_multilingu = pd.read_csv('./data/country_names_multilingual/IP2LOCATION-COUNTRY-MULTILINGUAL.CSV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File ./data/location_ref/countrycodes_coord.csv does not exist: './data/location_ref/countrycodes_coord.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2b716e1bbbc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# lookup country codes - coordinates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mco_from_cc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/location_ref/countrycodes_coord.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcountry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mco_from_cc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mco_from_cc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'country'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'AE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcountry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'latitude'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcountry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'longitude'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File ./data/location_ref/countrycodes_coord.csv does not exist: './data/location_ref/countrycodes_coord.csv'"
     ]
    }
   ],
   "source": [
    "# lookup country codes - coordinates\n",
    "co_from_cc = pd.read_csv('./data/location_ref/countrycodes_coord.csv')\n",
    "country = co_from_cc[co_from_cc['country'] == 'AE']\n",
    "(lat, long) = (country['latitude'].to_list()[0], country['longitude'].to_list()[0])\n",
    "lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LANG</th>\n",
       "      <th>LANG_NAME</th>\n",
       "      <th>COUNTRY_ALPHA2_CODE</th>\n",
       "      <th>COUNTRY_ALPHA3_CODE</th>\n",
       "      <th>COUNTRY_NUMERIC_CODE</th>\n",
       "      <th>COUNTRY_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AF</td>\n",
       "      <td>AFRIKAANS</td>\n",
       "      <td>AD</td>\n",
       "      <td>AND</td>\n",
       "      <td>20</td>\n",
       "      <td>Andorra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AF</td>\n",
       "      <td>AFRIKAANS</td>\n",
       "      <td>AE</td>\n",
       "      <td>ARE</td>\n",
       "      <td>784</td>\n",
       "      <td>Verenigde Arabiese Emirate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AF</td>\n",
       "      <td>AFRIKAANS</td>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>4</td>\n",
       "      <td>Afganistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AF</td>\n",
       "      <td>AFRIKAANS</td>\n",
       "      <td>AG</td>\n",
       "      <td>ATG</td>\n",
       "      <td>28</td>\n",
       "      <td>Antigua en Barbuda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AF</td>\n",
       "      <td>AFRIKAANS</td>\n",
       "      <td>AI</td>\n",
       "      <td>AIA</td>\n",
       "      <td>660</td>\n",
       "      <td>Anguilla</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LANG  LANG_NAME COUNTRY_ALPHA2_CODE COUNTRY_ALPHA3_CODE  \\\n",
       "0   AF  AFRIKAANS                  AD                 AND   \n",
       "1   AF  AFRIKAANS                  AE                 ARE   \n",
       "2   AF  AFRIKAANS                  AF                 AFG   \n",
       "3   AF  AFRIKAANS                  AG                 ATG   \n",
       "4   AF  AFRIKAANS                  AI                 AIA   \n",
       "\n",
       "   COUNTRY_NUMERIC_CODE                COUNTRY_NAME  \n",
       "0                    20                     Andorra  \n",
       "1                   784  Verenigde Arabiese Emirate  \n",
       "2                     4                  Afganistan  \n",
       "3                    28          Antigua en Barbuda  \n",
       "4                   660                    Anguilla  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_multilingu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EU country codes\n",
    "# https://abbreviations.yourdictionary.com/articles/list-of-europe-country-codes.html\n",
    "# Austria  - AT - AUT - 43\n",
    "\n",
    "# filter for Germany, Spain, France, Sweden\n",
    "sel_4 = ['DE', 'ES', 'FR', 'SE' ]\n",
    "\n",
    "# filter for European Countries\n",
    "sel_european_un = ['AT', 'BE', 'BG', 'HR', 'CY', 'CZ', 'DK', 'EE', 'FI', 'FR', 'DE',\n",
    "                  'GR', 'HU', 'IE', 'IT', 'LV', 'LT', 'LU', 'MT', 'NL', 'PO', 'PT', \n",
    "                   'RO', 'SK', 'SI', 'ES', 'SE']\n",
    "sel_c = sel_european_un\n",
    "\n",
    "country_codes = c_multilingu[c_multilingu['COUNTRY_ALPHA2_CODE'].isin(sel_c)]\n",
    "#country_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GA - irish\n",
    "# GL - galican\n",
    "# LT - lithuanian\n",
    "# LV - latvian\n",
    "# lb - luxembourgish\n",
    "# sk - slovak\n",
    "# sl - slovenian\n",
    "# nl - dutch, flemish\n",
    "# ro - romanian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for languages \n",
    "#https://www.loc.gov/standards/iso639-2/php/code_list.php\n",
    "lang_4 = ['DE', 'FR', 'ES', 'SV']   \n",
    "# EU + norway \n",
    "lang_european_un = ['DE', 'FR', 'HR', 'CS', 'DA', 'ET', 'FI', \n",
    "                    'EL',  'HU', 'GA', 'GL', 'IT', 'LT', 'LV', 'LB',\n",
    "                    'SK', 'SL', 'NL', 'PL', 'PT', 'RO', 'SV', 'NN','ES', 'SV']\n",
    "\n",
    "# assign current used languages list to \"lang\"\n",
    "lang = lang_european_un"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LANG</th>\n",
       "      <th>LANG_NAME</th>\n",
       "      <th>COUNTRY_ALPHA2_CODE</th>\n",
       "      <th>COUNTRY_ALPHA3_CODE</th>\n",
       "      <th>COUNTRY_NUMERIC_CODE</th>\n",
       "      <th>COUNTRY_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13798</th>\n",
       "      <td>NN</td>\n",
       "      <td>NORWEGIAN NYNORSK</td>\n",
       "      <td>IM</td>\n",
       "      <td>IMN</td>\n",
       "      <td>833</td>\n",
       "      <td>Man</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      LANG          LANG_NAME COUNTRY_ALPHA2_CODE COUNTRY_ALPHA3_CODE  \\\n",
       "13798   NN  NORWEGIAN NYNORSK                  IM                 IMN   \n",
       "\n",
       "       COUNTRY_NUMERIC_CODE COUNTRY_NAME  \n",
       "13798                   833          Man  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel = c_multilingu[c_multilingu['LANG'].isin(lang)]\n",
    "# # test\n",
    "sel[sel['COUNTRY_NAME']=='Man']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5726, 3364)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_nam_list = sel['COUNTRY_NAME'].to_list()\n",
    "\n",
    "# remove problem causing country names \n",
    "c_nam_list.remove('Man')\n",
    "\n",
    "\n",
    "# get unique country names\n",
    "c_nam_list_unique = list(set(c_nam_list))\n",
    "len(c_nam_list), len(c_nam_list_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = []\n",
    "with open(\"./data/06/01/00/30.json\") as f:\n",
    "    for line in f:\n",
    "        tweet_data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created_at': 'Mon Jun 01 06:30:00 +0000 2020',\n",
       " 'id': 1267342617102123016,\n",
       " 'id_str': '1267342617102123016',\n",
       " 'text': 'RT @Aaleeetorres_: Corrimos como 2 cuadras y los perdimos a la yuta jajajaj',\n",
       " 'source': '<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>',\n",
       " 'truncated': False,\n",
       " 'in_reply_to_status_id': None,\n",
       " 'in_reply_to_status_id_str': None,\n",
       " 'in_reply_to_user_id': None,\n",
       " 'in_reply_to_user_id_str': None,\n",
       " 'in_reply_to_screen_name': None,\n",
       " 'user': {'id': 1205152203742339079,\n",
       "  'id_str': '1205152203742339079',\n",
       "  'name': 'Niquitoo⚡',\n",
       "  'screen_name': 'Nicooo35914277',\n",
       "  'location': None,\n",
       "  'url': None,\n",
       "  'description': 'river plateee💓🤙🏽',\n",
       "  'translator_type': 'none',\n",
       "  'protected': False,\n",
       "  'verified': False,\n",
       "  'followers_count': 272,\n",
       "  'friends_count': 298,\n",
       "  'listed_count': 0,\n",
       "  'favourites_count': 5907,\n",
       "  'statuses_count': 685,\n",
       "  'created_at': 'Thu Dec 12 15:47:56 +0000 2019',\n",
       "  'utc_offset': None,\n",
       "  'time_zone': None,\n",
       "  'geo_enabled': False,\n",
       "  'lang': None,\n",
       "  'contributors_enabled': False,\n",
       "  'is_translator': False,\n",
       "  'profile_background_color': 'F5F8FA',\n",
       "  'profile_background_image_url': '',\n",
       "  'profile_background_image_url_https': '',\n",
       "  'profile_background_tile': False,\n",
       "  'profile_link_color': '1DA1F2',\n",
       "  'profile_sidebar_border_color': 'C0DEED',\n",
       "  'profile_sidebar_fill_color': 'DDEEF6',\n",
       "  'profile_text_color': '333333',\n",
       "  'profile_use_background_image': True,\n",
       "  'profile_image_url': 'http://pbs.twimg.com/profile_images/1249119444573605890/5T5VCt0W_normal.jpg',\n",
       "  'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1249119444573605890/5T5VCt0W_normal.jpg',\n",
       "  'default_profile': True,\n",
       "  'default_profile_image': False,\n",
       "  'following': None,\n",
       "  'follow_request_sent': None,\n",
       "  'notifications': None},\n",
       " 'geo': None,\n",
       " 'coordinates': None,\n",
       " 'place': None,\n",
       " 'contributors': None,\n",
       " 'retweeted_status': {'created_at': 'Mon Jun 01 01:55:52 +0000 2020',\n",
       "  'id': 1267273630527995908,\n",
       "  'id_str': '1267273630527995908',\n",
       "  'text': 'Corrimos como 2 cuadras y los perdimos a la yuta jajajaj',\n",
       "  'source': '<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>',\n",
       "  'truncated': False,\n",
       "  'in_reply_to_status_id': None,\n",
       "  'in_reply_to_status_id_str': None,\n",
       "  'in_reply_to_user_id': None,\n",
       "  'in_reply_to_user_id_str': None,\n",
       "  'in_reply_to_screen_name': None,\n",
       "  'user': {'id': 1194039156386729985,\n",
       "   'id_str': '1194039156386729985',\n",
       "   'name': 'Axeli📍',\n",
       "   'screen_name': 'Aaleeetorres_',\n",
       "   'location': None,\n",
       "   'url': None,\n",
       "   'description': '🧸',\n",
       "   'translator_type': 'none',\n",
       "   'protected': False,\n",
       "   'verified': False,\n",
       "   'followers_count': 463,\n",
       "   'friends_count': 233,\n",
       "   'listed_count': 0,\n",
       "   'favourites_count': 2668,\n",
       "   'statuses_count': 1625,\n",
       "   'created_at': 'Mon Nov 11 23:48:56 +0000 2019',\n",
       "   'utc_offset': None,\n",
       "   'time_zone': None,\n",
       "   'geo_enabled': False,\n",
       "   'lang': None,\n",
       "   'contributors_enabled': False,\n",
       "   'is_translator': False,\n",
       "   'profile_background_color': 'F5F8FA',\n",
       "   'profile_background_image_url': '',\n",
       "   'profile_background_image_url_https': '',\n",
       "   'profile_background_tile': False,\n",
       "   'profile_link_color': '1DA1F2',\n",
       "   'profile_sidebar_border_color': 'C0DEED',\n",
       "   'profile_sidebar_fill_color': 'DDEEF6',\n",
       "   'profile_text_color': '333333',\n",
       "   'profile_use_background_image': True,\n",
       "   'profile_image_url': 'http://pbs.twimg.com/profile_images/1258582536109854726/ybGxmyAP_normal.jpg',\n",
       "   'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1258582536109854726/ybGxmyAP_normal.jpg',\n",
       "   'profile_banner_url': 'https://pbs.twimg.com/profile_banners/1194039156386729985/1589694950',\n",
       "   'default_profile': True,\n",
       "   'default_profile_image': False,\n",
       "   'following': None,\n",
       "   'follow_request_sent': None,\n",
       "   'notifications': None},\n",
       "  'geo': None,\n",
       "  'coordinates': None,\n",
       "  'place': None,\n",
       "  'contributors': None,\n",
       "  'is_quote_status': False,\n",
       "  'quote_count': 0,\n",
       "  'reply_count': 0,\n",
       "  'retweet_count': 2,\n",
       "  'favorite_count': 10,\n",
       "  'entities': {'hashtags': [], 'urls': [], 'user_mentions': [], 'symbols': []},\n",
       "  'favorited': False,\n",
       "  'retweeted': False,\n",
       "  'filter_level': 'low',\n",
       "  'lang': 'es'},\n",
       " 'is_quote_status': False,\n",
       " 'quote_count': 0,\n",
       " 'reply_count': 0,\n",
       " 'retweet_count': 0,\n",
       " 'favorite_count': 0,\n",
       " 'entities': {'hashtags': [],\n",
       "  'urls': [],\n",
       "  'user_mentions': [{'screen_name': 'Aaleeetorres_',\n",
       "    'name': 'Axeli📍',\n",
       "    'id': 1194039156386729985,\n",
       "    'id_str': '1194039156386729985',\n",
       "    'indices': [3, 17]}],\n",
       "  'symbols': []},\n",
       " 'favorited': False,\n",
       " 'retweeted': False,\n",
       " 'filter_level': 'low',\n",
       " 'lang': 'es',\n",
       " 'timestamp_ms': '1590993000661'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the structure of the jsons\n",
    "tweet_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# place:\n",
    "# {\n",
    "#     'id': '09c3311ea17328e3', \n",
    "#     'url': 'https://api.twitter.com/1.1/geo/id/09c3311ea17328e3.json', \n",
    "#     'place_type': 'city', \n",
    "#     'name': 'Haldwani-Kathgodam', \n",
    "#     'full_name': 'Haldwani-Kathgodam, India', \n",
    "#     'country_code': 'IN', \n",
    "#     'country': 'India',\n",
    "#     'bounding_box': {\n",
    "#         'type': 'Polygon', 'coordinates': [[[\n",
    "#             79.125472, 28.982011], [79.125472, 29.414743], \n",
    "#             [79.98024, 29.414743], [79.98024, 28.982011]]]}, 'attributes': {}\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to postgres database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare postgres config\n",
    "HOST = 'localhost'\n",
    "USERNAME = 'postgres'\n",
    "PORT = '5432'\n",
    "DB = 'tweets_multilingu'\n",
    "PASSWORD = 'postgres'\n",
    "\n",
    "# Create a postgres connection and assign it to 'engine' variable\n",
    "engine = create_engine(f'postgres://{USERNAME}:{PASSWORD}@{HOST}:{PORT}/{DB}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_to_country_coords(country_name_multilingual):\n",
    "    # Get country coords\n",
    "    return '79.125472, 28.982011'\n",
    "\n",
    "def get_from_country_coords(country_code):\n",
    "    \"\"\"Function to retrieve country coordinates from ISO country codes\"\"\"\n",
    "    country = co_from_cc[co_from_cc['country'] == country_code]\n",
    "    (lat, long) = (country['latitude'].to_list()[0], country['longitude'].to_list()[0])\n",
    "    # Get country coords\n",
    "    return f'{lat}, {long}'\n",
    "\n",
    "def get_coordinates(bounding_coords, city_name, user_location):\n",
    "    if bounding_coords:\n",
    "        return bounding_coords\n",
    "    elif city_name:\n",
    "        # Lookup city name coordinates\n",
    "        return '79.125472, 28.982011'\n",
    "    elif user_location:\n",
    "        # Lookup user location\n",
    "        return '79.125472, 28.982011'\n",
    "    elif country_code:\n",
    "        # Lookup country code\n",
    "        return get_from_country_coords(country_code)\n",
    "\n",
    "def extract_url(urls):\n",
    "    found_url = ''\n",
    "    url_given = urls\n",
    "    if url_given != None:\n",
    "        for url in url_given:\n",
    "            found_url = url.get('url')\n",
    "    return found_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(data):\n",
    "    \"\"\" Loads transformed tweeets into the Postgres database\n",
    "    Parameters:\n",
    "    ------------\n",
    "    tweets: List of tweet dictionaries that were retrieved from the Twitter API \"\"\"\n",
    "\n",
    "    insert_query = \"\"\"INSERT INTO tweets_test (\n",
    "        tweet_id, \n",
    "        timestamp_ms,\n",
    "        tweet, \n",
    "        url_in_tweet, \n",
    "        user_url, \n",
    "        user_location, \n",
    "        user_followers_count, \n",
    "        user_verified, \n",
    "        user_statuses_count,\n",
    "        user_id,\n",
    "        user_created_at,\n",
    "\n",
    "        lang,  \n",
    "        from_coords,\n",
    "        from_country_coords,\n",
    "        to_country_coords,\n",
    "        tweet_country_code)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s);\"\"\"\n",
    "    \n",
    "    counter = 0 \n",
    "    counter_loc = 0 \n",
    "    counter_country_ment = 0 \n",
    "    # loop through list of jsons \n",
    "    for j in data:\n",
    "        # check for valid entries and if tweet json contains any location information \n",
    "        valid_entry = j.get('created_at')\n",
    "        user_loc = j.get('user', {}).get('location')\n",
    "        place_attr = j.get('place')\n",
    "        user_url = j.get('user', {}).get('url')\n",
    "        urls = j.get('entities', {}).get('urls')\n",
    "        \n",
    "        counter += 1 \n",
    "        \n",
    "        \n",
    "        if valid_entry != None and len(urls) != 0 and user_url != None and user_loc != None or place_attr != None:\n",
    "            print('entry with user loc or place attribute found')\n",
    "            counter_loc += 1 \n",
    "\n",
    "            \n",
    "            # loop through multilingual country list \n",
    "            for c_name_multi in c_nam_list_unique:\n",
    "                \n",
    "                \n",
    "                # check if one of the country names exist in tweet text\n",
    "                if c_name_multi in j['text']:\n",
    "                    counter_country_ment += 1\n",
    "                    print(c_name_multi, 'in tweet found')\n",
    "\n",
    "                    # get user dict\n",
    "                    user = j.get('user')\n",
    "                    # ger user_location if exits\n",
    "                    user_location = user.get('location')\n",
    "                            \n",
    "                    # get place dict if exists and extract first coordinate of the bounding box\n",
    "                    place = j.get('place')\n",
    "                    country_code = ''\n",
    "                    tweet_country_code = ''\n",
    "                    bounding_coords = ''\n",
    "                    city_name = ''\n",
    "                    from_coords = ''\n",
    "                    from_country_coords = ''\n",
    "\n",
    "                    if place != None:\n",
    "                        country_code = place.get('country_code')\n",
    "                        tweet_country_code = place.get('country_code')\n",
    "                        \n",
    "                        bounding_coords = ','.join(list(map(lambda n: str(n), place.get('bounding_box').get('coordinates')[0][0])))\n",
    "                        \n",
    "                        city_name = place.get('full_name')\n",
    "                        from_coords = get_coordinates(bounding_coords, city_name, user_location)\n",
    "                        from_country_coords = get_from_country_coords(country_code)\n",
    "                        \n",
    "                    to_country_coords = get_to_country_coords(c_name_multi)\n",
    "                    \n",
    "                    # get url mentionend in tweet from entities dict\n",
    "                    found_url = extract_url(j.get('entities').get('urls'))\n",
    "                    \n",
    "\n",
    "                    # insert values into postgres DB                             \n",
    "                    engine.execute(insert_query, (\n",
    "                        j['id'], #id\n",
    "                        j['timestamp_ms'], #timestamp_ms\n",
    "                        j['text'], #tweet\n",
    "                        found_url, #url_in_tweet\n",
    "                        user['url'], #user_url\n",
    "                        user_location, #user_location\n",
    "                        user['followers_count'], #user_followers_count\n",
    "                        user['verified'], #user_verified\n",
    "                        user['statuses_count'], #user_statuses_count\n",
    "                        user['id'], #user_id\n",
    "                        user['created_at'], #user_created_at\n",
    "                        \n",
    "                        j['lang'], #lang\n",
    "                        from_coords, #from_coords\n",
    "                        from_country_coords, #from_country_coords\n",
    "                        to_country_coords, #to_country_coords\n",
    "                        tweet_country_code #tweet_country_code\n",
    "                        )\n",
    "         \n",
    "                    )\n",
    "    \n",
    "    \n",
    "    print('scanned jsons :', counter, \n",
    "          '\\n with some location information and user url given :', counter_loc,\n",
    "          '\\n with some location information, user url and country name mentioned :',counter_country_ment)\n",
    "    \n",
    "        \n",
    "### MORE filters:\n",
    "# follwers count above certain threshold! - maybe filter that in postgres!?!\n",
    "\n",
    "\n",
    "# how to make sure that country mentioned is the same as from location country!?!\n",
    "# also in postgres? if 'countryname in local language == contains countryname in tweet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "India in tweet found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "Japan in tweet found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "Perú in tweet found\n",
      "entry with user loc or place attribute found\n",
      "Deutschland in tweet found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "entry with user loc or place attribute found\n",
      "scanned jsons : 3386 \n",
      " with some location information and user url given : 102 \n",
      " with some location information, user url and country name mentioned : 4\n"
     ]
    }
   ],
   "source": [
    "load(tweet_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### write os walk through all the files for the whole month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
